{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import autograd as ag\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv_layers= nn.Sequential(nn.Conv2d(1, 32, (3,3), padding=1),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2)),\n",
    "                                 nn.Conv2d(32, 64, (3,3), padding=1),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2)))\n",
    "        self.linear_layers = nn.Sequential(\n",
    "                                 nn.Linear(3136, 100),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(100, 50),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(50, 2),\n",
    "                                 nn.Softmax()\n",
    "                                 # nn.MaxPool2d((2,2))\n",
    "                                 )\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        conv_output = self.conv_layers(inp)\n",
    "        return self.linear_layers(conv_output.view(conv_output.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1, 128, (5, 5)), # 14\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, (5, 5)), # 18\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, (5, 5)), # 22\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, (3, 3)), # 24\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 8, (3, 3)), # 26\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 1, (3, 3)), # 28\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        return self.net(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inp = Variable(torch.rand( 1, 1, 28, 28))\n",
    "d = Discriminator()\n",
    "num_epochs = 100\n",
    "train_loader = data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor()])))\n",
    "test_loader = data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor()])))\n",
    "\n",
    "count =0\n",
    "for batch, (train_data, target) in enumerate(train_loader):\n",
    "    if count == 1000:\n",
    "        break\n",
    "    count +=1\n",
    "    # print(\" count : \", count)\n",
    "    # print(\"train : \", train_data)\n",
    "    # print(\"target : \", target)\n",
    "    for epoch in range(num_epochs):\n",
    "        output = d.forward(Variable(train_data))\n",
    "        optimizer = optim.Adam(d.parameters())\n",
    "        # target = Variable(target)\n",
    "        # target_t = torch.zeros(1, 10)\n",
    "        # print(target_t[0][target-1])\n",
    "        # target_t[0][target] = 1\n",
    "        target_t = torch.Tensor([[1, 0]])\n",
    "        # print(\"size \", target.size())\n",
    "        loss_obj = nn.MSELoss()\n",
    "        loss = loss_obj(output, Variable(target_t))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(\" epoch : \", epoch, \"loss : \", loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  0\n tot loss :  2.6263630390167236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  1\n tot loss :  2.6263608932495117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  2\n tot loss :  2.626352310180664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  3\n tot loss :  2.6263556480407715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  4\n tot loss :  2.626352548599243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  5\n tot loss :  2.626347064971924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  6\n tot loss :  2.6263468265533447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  7\n tot loss :  2.6263437271118164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  8\n tot loss :  2.626340627670288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  9\n tot loss :  2.6263375282287598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  10\n tot loss :  2.6263341903686523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  11\n tot loss :  2.626330852508545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  12\n tot loss :  2.626326560974121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  13\n tot loss :  2.6263232231140137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  14\n tot loss :  2.626317262649536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  15\n tot loss :  2.626315116882324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  16\n tot loss :  2.6263113021850586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  17\n tot loss :  2.6263065338134766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  18\n tot loss :  2.626302719116211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  19\n tot loss :  2.626296043395996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  20\n tot loss :  2.6262927055358887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  21\n tot loss :  2.6262874603271484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  22\n tot loss :  2.626282215118408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  23\n tot loss :  2.626277208328247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  24\n tot loss :  2.6262693405151367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  25\n tot loss :  2.626265525817871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  26\n tot loss :  2.62625789642334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  27\n tot loss :  2.6262521743774414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  28\n tot loss :  2.626246452331543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  29\n tot loss :  2.6262340545654297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  30\n tot loss :  2.6262311935424805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  31\n tot loss :  2.626211643218994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  32\n tot loss :  2.6262154579162598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  33\n tot loss :  2.626206874847412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  34\n tot loss :  2.626197338104248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  35\n tot loss :  2.626188278198242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  36\n tot loss :  2.6261773109436035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  37\n tot loss :  2.626157760620117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  38\n tot loss :  2.626155376434326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  39\n tot loss :  2.6261396408081055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  40\n tot loss :  2.626099109649658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  41\n tot loss :  2.6261134147644043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  42\n tot loss :  2.626101016998291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  43\n tot loss :  2.6260833740234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  44\n tot loss :  2.626068115234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  45\n tot loss :  2.6260509490966797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  46\n tot loss :  2.626028537750244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  47\n tot loss :  2.6260104179382324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  48\n tot loss :  2.6259899139404297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  49\n tot loss :  2.625964641571045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  50\n tot loss :  2.625936985015869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  51\n tot loss :  2.6259117126464844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  52\n tot loss :  2.6258814334869385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  53\n tot loss :  2.625845432281494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  54\n tot loss :  2.6258111000061035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  55\n tot loss :  2.6257691383361816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  56\n tot loss :  2.625723123550415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  57\n tot loss :  2.625627279281616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  58\n tot loss :  2.625609874725342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  59\n tot loss :  2.6255297660827637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  60\n tot loss :  2.6254725456237793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  61\n tot loss :  2.625389575958252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  62\n tot loss :  2.6252646446228027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  63\n tot loss :  2.6251697540283203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  64\n tot loss :  2.62503719329834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  65\n tot loss :  2.624814987182617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  66\n tot loss :  2.624666690826416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  67\n tot loss :  2.6244125366210938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  68\n tot loss :  2.6241073608398438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  69\n tot loss :  2.6237003803253174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  70\n tot loss :  2.6231236457824707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  71\n tot loss :  2.6223697662353516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  72\n tot loss :  2.621192455291748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  73\n tot loss :  2.619229316711426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  74\n tot loss :  2.614382266998291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  75\n tot loss :  2.6050729751586914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  76\n tot loss :  2.5571236610412598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  77\n tot loss :  0.8024200201034546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  78\n tot loss :  0.6633090972900391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  79\n tot loss :  0.6448723077774048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  80\n tot loss :  0.6386491060256958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  81\n tot loss :  0.6347925662994385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  82\n tot loss :  0.6327608227729797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  83\n tot loss :  0.6316505074501038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  84\n tot loss :  0.6306142807006836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  85\n tot loss :  0.6299906969070435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  86\n tot loss :  0.6295453310012817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  87\n tot loss :  0.6291459202766418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  88\n tot loss :  0.6288537979125977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  89\n tot loss :  0.6286616325378418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  90\n tot loss :  0.628399133682251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  91\n tot loss :  0.6282444000244141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  92\n tot loss :  0.6281161308288574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  93\n tot loss :  0.6279631853103638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  94\n tot loss :  0.6278784275054932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  95\n tot loss :  0.6277644634246826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  96\n tot loss :  0.6277391910552979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  97\n tot loss :  0.6276105642318726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  98\n tot loss :  0.6275485157966614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch :  99\n tot loss :  0.6274897456169128\n"
     ]
    }
   ],
   "source": [
    "g = Generator()\n",
    "z = torch.rand(1, 1, 10, 10)\n",
    "gen_epochs = 1000\n",
    "# print(g.forward(Variable(z)))\n",
    "# print(len(train_loader[0]))\n",
    "count = 0\n",
    "for batch, (train_data, target) in enumerate(test_loader):\n",
    "    if count >= 100:\n",
    "        break\n",
    "    count += 1\n",
    "    for epoch in range(gen_epochs):\n",
    "        ce_loss = nn.CrossEntropyLoss()\n",
    "        d_loss = ce_loss(d.forward(Variable(train_data)), Variable(torch.LongTensor([1])))\n",
    "        z = Variable(torch.rand(1, 1, 10, 10))\n",
    "        g_out = g.forward(z)\n",
    "        # print(g_out)\n",
    "        g_loss = ce_loss(d.forward(g_out), Variable(torch.LongTensor([1])))\n",
    "        tot_loss = d_loss + g_loss\n",
    "        optimizer_d = optim.SGD(d.parameters(), lr=1e-3)\n",
    "        optimizer_g = optim.SGD(g.parameters(), lr=1e-3)\n",
    "        optimizer_d.zero_grad()\n",
    "        optimizer_g.zero_grad()\n",
    "        tot_loss.backward()\n",
    "        optimizer_d.step()\n",
    "        optimizer_g.step()\n",
    "        # optimizer_g = optim.SGD(g.parameters(), lr=1e-3)\n",
    "        # g_loss = ce_loss(d.forward(g.forward(z)), Variable(torch.LongTensor(1)))\n",
    "        # g_loss.backward()\n",
    "        # optimizer_g.step()\n",
    "        if epoch == 99:\n",
    "            print(\" batch : \", batch)\n",
    "            print(\" tot loss : \", tot_loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112042710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_images = 5\n",
    "for i in range(num_images):\n",
    "    z = Variable(torch.rand(1, 1, 10, 10))\n",
    "    img = g(z)\n",
    "    img = img.data.numpy()\n",
    "    # img = img.reshape(28, 28)\n",
    "    pt.imshow(img[0][0])\n",
    "    # print(i, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}